---
title: "Aplicação do PSF com validação cruzada a séries de vazão naturalizada"
author: "Jerônimo Acker D'Ornellas"
date: "24/05/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objetivo 

O objetivo do testePSF é realizar a aplicação do algoritmo PSF em séries hidrológicas e comparar o desempenho do algoritmo com outros métodos univariados amplamente usados para os dados das bacia hidrográficas da ONS. Neste arquivo aplicaremos a validação cruzada aos postos da ONS. A partir da validação cruzada esperamos obter uma avaliação robusta do desempenho do algoritmo PSF e também selecionar, a partir da busca de um padrão, os parâmetros ótimos.

## Pré-requisitos

Pacotes necessários:

```{r, message=FALSE}
if(!require(PSF)) install.packages("PSF")
if(!require(timetk)) remotes::install_github("business-science/timetk")

pacotes <- c(
  "dplyr",
  "here",
  "usethis",
  "data.table",
  "HEobs",
  "PSF",
  "tidyverse",
  "lubridate",
  "fs",
  "checkmate",
  "xts",
  "hydroGOF",
  "ModelMetrics",
  "forecast",
  "timetk",
  "tibble",
  "tidygeocoder",
  "geobr"
)
# Carregar os pacotes
easypackages::libraries(pacotes)
```

Scripts:

```{r}
source(here('R', 'load-data.R'))
source(here('R', 'utils.R'))
```

## Dados de vazão

Os dados importados de vazão devem ser regularmente espaçados no tempo. Esta adequação das séries diárias, se necessária, pode ser realizada com a função `complete_dates()` do pacote **`{lhmetools}`**. Assim assegura-se que todas estações possuam 1 observação por dia e sem datas faltantes.

```{r}
qnat_data <- qnat_dly_ons() %>%
  select(date, qnat, code_stn) %>%
  lhmetools::complete_dates(group = "code_stn")
glimpse(qnat_data)
```


Observam-se dados faltantes na série, então selecionaremos através da função `apply_cmonth` somente os meses com pelo menos 28 observações válidas. Para robustez da avaliação consideraremos apenas anos que atendam ao critério de disponibilidade nos 12 meses do ano e verificamos se a série é múltipla de 12 como requisito da aplicação do PSF através da função `apply_cyears`.

```{r}
# Média mensal das observações de vazão para todos os postos
qnat_mly <- qnat_data %>% 
  apply_cmonth(., ndays_thresh = 28) %>% 
  group_by(code_stn) %>% 
  nest() %>% 
  mutate(
    data = map(data, apply_cyears)
  )
```

## Validação cruzada aplicada ao posto 287

A validação cruzada é um método bastante utilizado não só para obter uma estimativa robusta do desempenho de um modelo, mas também para selecionar os melhores hiperparâmetros (parâmetros que são definidos antes de treinar um modelo). Este método irá ser usado na série hidrológica do posto de código 287 da ONS, o qual obtivemos o melhor desempenho utilizando a técnica de previsão PSF para os dos últimos anos da série. Com isso, buscamos obter uma estimativa mais robusta do algoritmo de previsão e selecionar valores ótimos para os parâmetros `k` e `w`.

```{r}
qnatmly_287 <- qnat_mly %>%
  sel_station(., 287) %>%
  unnest(cols = data) %>%
  ungroup() %>%
  select(date, qnat_obs)
summary(qnatmly_287)
```


Separaremos os dados em um conjunto de treinamento e outro de teste, tal como feito anteriormente, só que dessa vez realizaremos previsões para um horizonte de 12 meses. A ideia é usar o conjunto de dados de teste após a validação cruzada para avaliar o desempenho das previsões utilizando os parâmetros selecionados.


```{r}
# Dados de treinamento sem o último ano
train287_qmly <- get_traindt(qnatmly_287, n_years = 1)
summary(train287_qmly)
# Dados para avaliação do PSF
test287_qmly <- get_testdt(qnatmly_287, n = 12)
summary(test287_qmly)
```


Os dados de treinamento serão divididos em duas partições: treinamento e validação. Nessa forma de divisão teremos a partição de validação sempre a frente da partição de treinamento. A função `time_series_cv` do pacote `timetk` nos permite criar uma plano de amostragem começando com as observações mais atuais da série. A partir do parâmetro `assess` definimos que a partição da validação deverá ser formada de  12 meses de observações e o parâmetro `skip` fornece o número de meses que serão pulados em cada divisão. O número de divisões é selecionado pelo parâmetro `slice_limit` e um número não fixo da janela foi definido através do parâmetro `cumulative`. Aumentando o número de divisões teremos uma avaliação mais robusta do modelo, porém há um maior custo computacional.

```{r}
resample_qmly287 <- time_series_cv(
  data = train287_qmly,
  assess = "12 months",
  skip = "36 months",
  cumulative = TRUE,
  slice_limit = 15
)

# Visualização do plano de amostragem
# resample_qmly287 %>%  plot_time_series_cv_plan(date,qnat_obs, .interactive = FALSE)
```

 Aplicaremos o PSF a todas as divisões do conjunto de treinamento e uma coluna é adicionada com as previsões usando a média dos parâmetros `k` e `w`.


```{r}
qmly287_slices <- resample_qmly287 %>%
  tk_time_series_cv_plan() %>%
  nest(date, qnat_obs) %>%
  pivot_wider(names_from = .key, values_from = data)

# Previsões usando um horizonte de 12 meses
cv287_qmly <- qmly287_slices %>%
  mutate(
    qnat_pred = map(
      training,
      ~ psf_reprod(.x, n = 12)
    ),
    model = map(
      training,
      ~ psf_reprod(.x, n = 12, predict = FALSE)
    ),
    cvparams = map(model, get_cvpar)
  )


# Média dos parâmetros k e w (2 e 3)

# cvm_params <- round(Reduce("+", cv287_qmly[["cvparams"]])
# / length(cv287_qmly[["cvparams"]]), 0)

# opção de código mais legível
params <- cv287_qmly[["cvparams"]] %>%
  map_dfr(~.x)

cv_med_params <- params %>%
  summarise(across(c(k, w), ~ round(mean(.x))))
cv_mod_params <- params %>%
  summarise(across(c(k, w), moda))


# Adicionando  coluna com as  prevs usando parâmetros médios
cv287_qmly <- cv287_qmly %>%
  mutate(qnat_medpar_pred = map(
    training,
    ~ psf_cvparam(.x, n = 12, params = cv_med_params)
  ),
  qnat_modpar_pred = map(
    training,
    ~ psf_cvparam(.x, n = 12, params = cv_mod_params)
  ))
```

Iremos comparar o desempenho do modelo com e sem a seleção dos parâmetros pela média.


```{r}
avalcv_m287 <- cv287_qmly %>%
  select(-c("model", "training", "cvparams")) %>%
  group_by(.id) %>%
  #unnest(cols =  c(testing, qnat_pred)) %>%
  unnest(cols =  c(testing, qnat_pred, qnat_medpar_pred, qnat_modpar_pred)) %>%
  summarise(
    KGEpred = KGE(sim = qnat_pred, obs = qnat_obs),
    KGEmedpar = KGE(sim = qnat_medpar_pred, obs = qnat_obs),
    KGEmodpar = KGE(sim = qnat_modpar_pred, obs = qnat_obs)
  )  %>% 
  #mutate(.id = factor(.id, levels = .id[order(KGEmedpar)])) %>% 
  pivot_longer(
    cols = -c(.id),
    names_to = "metric",
    values_to = "valor"
  )

# avalcv_m287 %>%
# ggplot(aes(x = .id, y = valor)) +
#   geom_col() + 
#   facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(avalcv_m287$metric)) + 
#   theme(axis.text.x = )


avalcv_m287 %>%
  select(-.id, KGE = valor) %>%
  #pivot_longer(cols = -code_stn, names_to = "KGE", values_to = "valor") %>%
  ggplot(aes(metric,KGE,colour = metric)) +
  geom_boxplot()

# Probabilidade de excedência do KGE (Prob(KGE>=x))
avalcv_m287 %>%
 select(-.id, KGE = valor) %>% 
  group_by(metric) %>%
  mutate(prob_exc = 1- percent_rank(KGE)) %>%
  mutate(prob_exc = if_else(prob_exc == 1, 0.9999, prob_exc)) %>% 
  ungroup() %>%
  ggplot(aes(x = prob_exc, y = KGE, color = metric)) +
  geom_line() +
  #geom_hline(yintercept = c(-0.41, 0.3), linetype = c(3, 2)) +
  geom_hline(yintercept = c(0.3), linetype = c(2)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + 
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6))

  
```

```{r}
avalcv_m287 %>%
  group_by(metric) %>%
  summarise(
    valor = mean(valor)
  )
```



Verificaremos o desempenho do modelo utilizando os parâmetros médios no conjunto de dados de teste (aqui corresponde a apenas 1 ano).


```{r}
# Previsões feitas com os parâmetros médios
pcv287_medpar <- psf_cvparam(train287_qmly,
  n = 12,
  params = cv_med_params
)
pcv287_modpar <- psf_cvparam(train287_qmly,
  n = 12,
  params = cv_mod_params
)

# Previsões sem a seleção dos parâmetros
preds287_qmly <- psf_reprod(train287_qmly, n = 12)

# Previsões e observações
pobs287cv_qmly <- mutate(test287_qmly,
  qnat_pred = preds287_qmly,
  qnat_medpar_pred = pcv287_medpar,
  qnat_modpar_pred = pcv287_modpar
)

avalcvmpar_287 <- pobs287cv_qmly %>%
  summarise(
    KGE = KGE(sim = qnat_pred, obs = qnat_obs),
    KGE_medpar = KGE(sim = qnat_medpar_pred, obs = qnat_obs),
    KGE_modpar = KGE(sim = qnat_modpar_pred, obs = qnat_obs)
  )
avalcvmpar_287
```

Observamos, baseado na métrica KGE, uma pequena melhora no modelo utilizando a seleção dos parâmetros pela média.


```{r}
posto287cv_xts <- xts(pobs287cv_qmly[,c("qnat_obs","qnat_modpar_pred","qnat_medpar_pred")], 
                   order.by = as.Date(pobs287cv_qmly[["date"]]))
forecast::autoplot(posto287cv_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```




## Validação cruzada aplicada a todos os 87 postos


```{r}
#postos_top10 <- c(287,295,145,281,278,291,279,99,277,190)
#qnat_mly_top10 <- filter(qnat_mly, code_stn %in% postos_top10)
  
# Vazão prevista 
# resample_qmly <- qnat_mly_top10 %>%
#   mutate(dados = map(data, time_series_cv,
#                      initial = "30 years",  # Treinamento(seta para um valor fixo)
#                      assess = "12 months", # Validação(seta para um valor fixo)
#                      skip = "12 months",   # cada resample tem um intervalo de 12 meses
#                      cumulative = FALSE,
#                      slices_limit = n()
#   )) %>% 
#   select(code_stn, dados) 

set.seed(1)

resample_qmly <- qnat_mly %>%
  mutate(dados = map(data, time_series_cv,
                     #initial = "30 years",  # Treinamento(seta para um valor fixo)
                     assess = "12 months", # Validação(seta para um valor fixo)
                     skip = "12 months",   # cada resample tem um intervalo de 12 meses
                     cumulative = TRUE,    # Conj de treinamento varia 
                     slice_limit = 10     # Cada resample tem 10 partições 
  )) %>% 
  select(code_stn, dados) 


# Plano de amostragem 
resample_qmlyplan <-  resample_qmly %>% 
  mutate(
    dados = map(dados,tk_time_series_cv_plan)
) 

# Plano de amostragem "aninhado"
resample_qmlyplan_nested <- resample_qmlyplan %>%
  mutate(dados = map(dados, ~ .x %>%
    group_by(.id, .key) %>%
    nest())) 

# Plano de amostragem no formato arrumado
resample_qmlyplan_tidy <- resample_qmlyplan_nested %>%
  mutate(dados = map(dados, ~ .x %>%
    pivot_wider(names_from = .key, values_from = data)))
```


Visualizar plot do plano de amostragem para uma estação.

```{r}
resample_vis <- qnat_mly %>%
  mutate(dados = map(data, time_series_cv,
    # initial = "30 years",  # Treinamento(seta para um valor fixo)
    assess = "12 months", # Validação(seta para um valor fixo)
    skip = "12 months", # cada resample tem um intervalo de 12 meses
    cumulative = TRUE, # Conj de treinamento varia
    slice_limit = 10 # Cada resample tem 10 partições
  ))

# Seleciona o plano de amostragem CV da estação 6 
pamos_stn6 <- resample_vis %>%
  mutate(
    dados = map(dados, tk_time_series_cv_plan)
  ) %>% 
  filter(code_stn == 6) 
        
pamos_stn6 <- pamos_stn6$dados 
pamos_stn6 <- pamos_stn6[[1]]

pamos_stn6 %>%
  plot_time_series_cv_plan(date,
    qnat_obs,
    .facet_ncol = 2,
    .line_alpha = 0.5,
    .interactive = FALSE,
    .title = "Plano de validação cruzada de séries temporais"
  )
```




```{r}

if(fs::file_exists(here('output', 'cv_qmly_2methods.rds'))){
  
  cv_qmly <- readRDS(here("output", "cv_qmly_2methods.rds"))
  
} else {
  
  #Aplicação do algoritmo para cada partição cv do conjunto de dados de cada posto
tictoc::tic()
cv_qmly <- resample_qmlyplan_tidy %>%
  mutate(
    prev = map(dados, ~ .x %>%
      mutate(
        qnat_prev = map(
          training,
          ~ psf_reprod(.x,
            n = 12,
            predict = TRUE
          )
        ),
        model = map(
          training,
          ~ psf_reprod(.x,
            n = 12,
            predict = FALSE
          )
        )
      ))
  )

tictoc::toc()
#613.854 sec elapsed (~10 min)

# adicionando parametros dos modelos de cada slice
cv_qmly <- cv_qmly %>%
  mutate(prev = map(prev, ~ .x %>%
    ungroup() %>%
    mutate(cvparams = map(
      model,
      ~ .x %>%
        get_cvpar() #%>% flatten_int()
    ))))

## check 
# cv_qmly[["prev"]][[1]]
# cv287_qmly

# Salva os resultados
saveRDS(cv_qmly, file = here('output', 'cv_qmly_2methods.rds'))

}
```


## Previsões usando a média e a moda dos parâmetros para o período de treinamento 


### Moda e média dos parâmetros 

```{r}
# Carrega os dados com modelos e previsões de cada slice
#cv_qmly <- readRDS(here("output", "cv_qmly.rds"))

cv_qmly <- cv_qmly %>%
  ungroup() %>%
  # Seleciona apenas as colunas 
  select(-dados) %>% 
  rename(dados = prev)

#cv_qmly[["dados"]][[1]]
#cv_qmly[["dados"]][[1]][["cvparams"]]

# Seleciona apenas as previsões e os dados de teste para a avaliação
#cv_qmly_aval <- cv_qmly %>% 
#  mutate(dados = map(dados, ~ .x %>% 
#                       select(-training)))

# agrupa dados por estacao
by_stn <- cv_qmly %>%
  group_by(code_stn) 

# obtem a moda e a media dos parametros nas slices
by_stn <- mutate(by_stn,
  params_med = map(
    dados,
    ~ .x %>%
      select(cvparams) %>%
      map_dfr(~ .x %>% map_dfr(~.x) %>% 
            summarise(across(c(k, w), ~ round(mean(.x)))))
    #%>%
    #  map(~ .x %>% summarise(across(c(k, w), ~ round(mean(.x)))))
  ),
  params_mod = map(
    dados,
    ~ .x %>%
      select(cvparams) %>%
      map_dfr(~ .x %>% map_dfr(~.x) %>% 
            summarise(across(c(k, w), moda)))
    #%>%
    #  map(~ .x %>% summarise(across(c(k, w), ~ round(mean(.x)))))
  )
) 

by_stn[["params_med"]]
by_stn[["params_mod"]]
by_stn[["dados"]][[1]]
```

### Previsões para o período de teste 

```{r}
tictoc::tic()

preds_test <- map_df(
  by_stn$code_stn,
  function(icode) {
    # icode = 6
    data_stn <- filter(by_stn, code_stn == icode)

    pars_med <- unlist(data_stn$params_med)
    pars_mod <- unlist(data_stn$params_mod)

    data <- data_stn %>%
      ungroup() %>%
      select(dados) %>%
      unnest(dados) %>%
      mutate(
        code_stn = icode,
        preds_med = map(
          training,
          ~ .x %>% psf_cvparam(n = 12, params = pars_med)
        ),
        preds_mod = map(
          training,
          ~ .x %>% psf_cvparam(n = 12, params = pars_mod)
        )
      ) %>%
      relocate(code_stn)
  }
)
tictoc::toc()
# 36.773 sec elapsed
preds_test
```


### Avaliação usando KGE

Cálculo do KGE para as previsões de cada slice.

```{r}
cv_aval <- preds_test %>%
  select(code_stn, testing, contains("preds_")) %>%
  # 870 (10 slices x 87 stns) x 12 meses (periodo teste)
  unnest(cols = c(testing, preds_med, preds_mod)) %>%
  group_by(code_stn) %>%
  summarise(
      KGE_parsmed = KGE(sim = preds_med, obs = qnat_obs),
      KGE_parsmod = KGE(sim = preds_mod, obs = qnat_obs)
    ) 
cv_aval_long <- cv_aval %>%
  pivot_longer(cols = -code_stn, names_to = "metric", values_to = "KGE") %>%
  mutate(metric = str_replace_all(metric, "KGE_", ""))

```

Gráficos do KGE.

```{r}
bxplot_kge <- cv_aval_long %>%
  #pivot_longer(cols = -code_stn, names_to = "KGE", values_to = "valor") %>%
  ggplot(aes(metric, KGE, fill = metric)) +
  geom_boxplot() 
bxplot_kge  

# Probabilidade de excedência do KGE (Prob(KGE>=x))
plot_pexc <- cv_aval_long %>%
  arrange(metric) %>%
  group_by(metric) %>%
  mutate(prob_exc = 1- percent_rank(KGE)) %>%
  mutate(prob_exc = if_else(prob_exc == 1, 0.9999, prob_exc)) %>% 
  ungroup() %>%
  ggplot(aes(x = prob_exc, y = KGE, color = metric)) +
  geom_line() +
  #geom_hline(yintercept = c(-0.41, 0.3), linetype = c(3, 2)) +
  geom_hline(yintercept = c(0.3), linetype = c(2)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + 
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6))
plot_pexc
```


```{r}
teste <- filter(cv_aval_long,grepl('parsmod',metric))
  
resultados <- teste %>% 
   filter(KGE >= 0.3) #%>% 
 # nrow() #67.81609195%
```

```{r}
teste %>% 
   filter(KGE >= 0.3) %>% 
   nrow() #67.81609195%
```


```{r}
teste %>% 
   filter(KGE >= -0.47) %>% #View()
  nrow() #100%
```



> Instruções: 
>
> - revisar o código para ver se a avaliação faz sentido para você.
> 
> - atualizar resumo com os resultados (usar a moda)
>
> - replicar gráfico da pexc com pontos coloridos para identificar o desempenho por região
>
> - fazer boxplot do KGE por região das BHs


### Análise dos resultados

Seleciona apenas os resultados do modelo do PSF usando a seleção dos parâmetros
pela moda.

```{r}
aval_pmod <- filter(cv_aval_long,grepl('parsmod',metric)) %>% 
  select(code_stn,KGE)
```

Dados com as coordenadas das estações.

```{r}
# dropbox_link <- file.path('https://www.dropbox.com/s/d40adhw66uwueet/',
#                 'VazoesNaturaisONS_D_87UHEsDirceuAssis_2018.dat?dl=1')
#   tmp_file <- fs::file_temp()
#   download.file(
#     url = dropbox_link,
#     destfile = tmp_file,
#     mode = "wb"
#   )
# 
# postos_info <- extract_metadata(tmp_file, informative = TRUE)
# latlog <- postos_info %>% 
#   select(latitude,longitude)
# 
# saveRDS(postos_info, file = here('output', 'coord_postos.rds'))

postos_info <-  readRDS(here("output", "coord_postos.rds"))
```

Subsistemas do Sistema Interligado Nacional.

```{r}
subsis <- list(
  seco = c("Minas Gerais", "Goiás", "Mato Grosso", "Mato Grosso do Sul", "São Paulo", "Rio de Janeiro", "Espírito Santo"),
  norte = c("Acre", "Amapá", "Amazonas", "Pará", "Rondônia", "Roraima", "Tocantins"),
  sul = c("Rio Grande do Sul", "Santa Catarina", "Paraná"),
  nord = c("Alagoas", "Bahia", "Ceará", "Maranhão", "Paraíba", "Pernambuco", "Piauí", "Rio Grande do Norte", "Sergipe")
)
```


Resultado da métrica KGE para cada estação com informação do estado e subsistema.

```{r}
# reg_postos <- postos_info %>%
#   reverse_geocode(lat = latitude, long = longitude, method = 'osm', full_results = TRUE) %>%
#   dplyr::select(latitude,longitude,estacao_codigo,address,state)
# 
# 
# saveRDS(reg_postos, file = here('output', 'reg_postos.rds'))

# Localizações dos estados das estações
reg_postos<- readRDS(here("output", "reg_postos.RDS")) %>% 
  rename(code_stn = estacao_codigo) %>% 
  select(code_stn,state)


# Adiciona coluna com os subsistemas de cada estado
reg_postos$subsistemas <- sapply(reg_postos$state, 
                 function(x) names(subsis)[grep(x,subsis)])


# Junta as estações e localização com os valores da métrica KGE
avalpmod_reg <- aval_pmod %>% 
  inner_join(
    .,
    reg_postos,
    by = "code_stn"
  )  
```


Boxplot por região das Bacias Hidrográficas

```{r}
# Muda nome das colunas e linhas para melhorar a visualização do boxplot
avalpmod_reg_tidy <- avalpmod_reg %>%
  rename(Subsistemas = subsistemas) %>% 
  mutate(Subsistemas = recode(Subsistemas, nord = 'Nordeste',
                              norte = 'Norte',
                              seco = "Sudeste/Centro-Oeste",
                              sul = "Sul")) 

avalpmod_reg_tidy %>% ggplot(aes(x = Subsistemas, y = KGE)) +
  geom_boxplot(aes(fill = Subsistemas),
    color = "black",
    outlier.size = 3
  ) +
  # coord_flip() +
  # facet_wrap(~stats, ncol = 2) +
  # labs(x = "Value", y = "Frequency") +
  theme_bw() +
  theme(
    #plot.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text = element_text(size=20)
  )
```


Gráfico com cores dos pontos representando os subsistemas das estações e o tamanho relacionado ao desempenho do modelo de acordo com a métrica KGE.

```{r}
# Para fazer a junção
postos_info <- rename(postos_info,code_stn = estacao_codigo)
# Junta as informações das coordenadas para o plot
avalpmod_coord <- avalpmod_reg_tidy %>% 
  inner_join(.,
             postos_info,
             by = "code_stn")

states <- read_state(year=2019)

no_axis <- theme(axis.title=element_blank(),
                   axis.text=element_blank(),
                   axis.ticks=element_blank())

ggplot() +
  geom_sf(data = states, fill = "#FFFFFF", color = "#000000", size = .15, show.legend = TRUE) +
  # labs(subtitle = "Estações do SIN", size = 8) +
  theme_minimal() +
  no_axis +
  geom_point(
    data = avalpmod_coord,
    aes(
      x = longitude,
      y = latitude,
      color = Subsistemas,
      size = KGE
    )
  ) +
  # scale_size_continuous(name = "Estações") +
  theme(
    panel.border = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  ) #+
   #theme_bw() 
```


> - replicar gráfico da pexc com pontos coloridos para identificar o desempenho por região

Probabilidade de excedência 

```{r}
avalpmod_exc <- avalpmod_reg_tidy %>% 
  select(code_stn,KGE,Subsistemas)

# Probabilidade de excedência do KGE (Prob(KGE>=x))
plot_pexc_reg <- avalpmod_exc %>%
  arrange(KGE) %>%
  group_by(Subsistemas) %>%
  mutate(prob_exc = 1 - percent_rank(KGE)) %>%
  mutate(prob_exc = if_else(prob_exc == 1, 0.9999, prob_exc)) %>%
  ungroup() %>%
  ggplot(aes(x = prob_exc, y = KGE, color = Subsistemas)) +
  labs(x = "Probabilidade de Excedência") +
  geom_point(size = 5, aes(shape = Subsistemas)) +
  # geom_hline(yintercept = c(-0.41, 0.3), linetype = c(3, 2)) +
  geom_hline(yintercept = c(0.3), linetype = c(2)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 6)) +
  theme_bw() +
  theme(
    # plot.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text = element_text(size = 20)
  ) 

plot_pexc_reg
```

```{r}
avalpmod_exc %>% 
  group_by(Subsistemas) %>% 
  select(-code_stn) %>% 
  summarize_all("mean") %>% View()
```


Análise da quantidade de postos em cada região em relação a valores da métrica KGE.


```{r}
# Quantidade de estações por região
preg <- avalpmod_reg_tidy %>%
  group_by(Subsistemas) %>%
  count()


# KGE >= 0.3
preg_03 <- avalpmod_reg_tidy %>% 
  group_by(Subsistemas) %>% 
  filter(KGE >= 0.3) %>% 
  count() 
```



## Análise usando outras métricas (já usando o modelo da moda)


```{r}
cv_metricas <- preds_test %>%
  select(code_stn, testing, contains("preds_")) %>%
  # 870 (10 slices x 87 stns) x 12 meses (periodo teste)
  unnest(cols = c(testing,preds_mod)) %>%
  group_by(code_stn) %>%
  summarise(
      KGE = KGE(sim = preds_mod, obs = qnat_obs),
      PBIAS = pbias(sim = preds_mod, obs = qnat_obs),
      NRMSE = nrmse(sim = preds_mod, obs = qnat_obs),
      NSE =NSE(sim = preds_mod, obs = qnat_obs)
    ) 
# cv_aval_metricas <- cv_metricas %>%
#   pivot_longer(cols = -code_stn, names_to = "metric", values_to = "Valor") #%>%
#   mutate(metric = str_replace_all(metric, "KGE_", ""))
```


Boxplot PBIAS e NRMSE

```{r}
aval_metricas <- cv_metricas %>%
  inner_join(
    .,
    reg_postos,
    by = "code_stn"
  )
```


```{r}
aval_metricas_reg <- aval_metricas %>%
  rename(Subsistemas = subsistemas) %>%
  mutate(Subsistemas = recode(Subsistemas,
    nord = "Nordeste",
    norte = "Norte",
    seco = "Sudeste/Centro-Oeste",
    sul = "Sul"
  ))

# PBIAS
aval_pbias <- aval_metricas_reg %>% ggplot(aes(x = Subsistemas, y = PBIAS)) +
  geom_boxplot(aes(fill = Subsistemas),
    color = "black",
    outlier.size = 3
  ) +
  # coord_flip() +
  # facet_wrap(~stats, ncol = 2) +
  # labs(x = "Value", y = "Frequency") +
  theme_bw() +
  theme(
    # plot.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text = element_text(size = 20)
  )
```

```{r}
# ggsave(plot = aval_pbias, file = "grafico.png",
#         type = "cairo-png",  bg = "transparent",
#         width = 50, height = 30, units = "cm", dpi = 800)
```

```{r}
aval_nrmse <- aval_metricas_reg %>% ggplot(aes(x = Subsistemas, y = NRMSE)) +
  geom_boxplot(aes(fill = Subsistemas),
    color = "black",
    outlier.size = 3
  ) +
  # coord_flip() +
  # facet_wrap(~stats, ncol = 2) +
  # labs(x = "Value", y = "Frequency") +
  theme_bw() +
  theme(
    # plot.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text = element_text(size = 20)
  )
```


Comparação com outros artigos (NSE)

```{r}
aval_nse <- aval_metricas_reg %>% ggplot(aes(x = Subsistemas, y = NSE)) +
  geom_boxplot(aes(fill = Subsistemas),
    color = "black",
    outlier.size = 3
  ) +
  # coord_flip() +
  # facet_wrap(~stats, ncol = 2) +
  # labs(x = "Value", y = "Frequency") +
  theme_bw() +
  theme(
    # plot.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text = element_text(size = 20)
  )
```

```{r}
aval_metricas_reg %>% 
  select(code_stn,NSE) %>% View()
```

