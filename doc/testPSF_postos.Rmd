---
title: "Aplicação do algoritmo PSF a séries de vazão naturalizada"
author: "Jerônimo Acker D'Ornellas"
date: "08/04/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
#rm(list = ls())
knitr::opts_chunk$set(
  #echo = FALSE,
  comment = "#>",
  collapse = TRUE
)
```

## Objetivo 

O objetivo do testePSF é realizar a aplicação do algoritmo PSF em séries hidrológicas e comparar o desempenho do algoritmo com outros métodos univariados amplamente usados para os dados das bacia hidrográficas da ONS. 

## Pré-requisitos

Pacotes necessários:


```{r, message=FALSE}
if(!require(PSF)) install.packages("PSF")
if(!require(timetk)) remotes::install_github("business-science/timetk")
# tive que usar o tidyr do github
# por causa de erro no unnest()
#  Error: Input must be list of vectors
# remotes::install_github("tidyverse/tidyr")
pacotes <- c(
  "here",
  "usethis",
  "data.table",
  "HEobs",
  "PSF",
  "tidyverse",
  "lubridate",
  "fs",
  "checkmate",
  "xts",
  "hydroGOF",
  "ModelMetrics",
  "forecast",
  "timetk"
)
# Carregar os pacotes
easypackages::libraries(pacotes)
```

Scripts:

```{r}
source(here('R', 'load-data.R'))
source(here('R', 'utils.R'))
```


### Dados de vazão

Os dados importados de vazão devem ser regularmente espaçados no tempo. Esta adequação das séries diárias, se necessária, pode ser realizada com a função `complete_dates()` do pacote **`{lhmetools}`**. Assim assegura-se que todas estações possuam 1 observação por dia e sem datas faltantes.

```{r}
qnat_data <- qnat_dly_ons() %>%
  select(date, qnat, code_stn) %>%
  lhmetools::complete_dates(group = "code_stn")
glimpse(qnat_data)
```



## Aplicação do PSF para os principais postos da ONS

Observam-se dados faltantes na série, então selecionaremos através da função `apply_cmonth` somente os meses com pelo menos 28 observações válidas. Para robustez da avaliação consideraremos apenas anos que atendam ao critério de disponibilidade nos 12 meses do ano e verificamos se a série é múltipla de 12 como requisito da aplicação do PSF através da função `apply_cyears`.

```{r}
# Média mensal das observações de vazão para todos os postos
qnat_mly <- qnat_data %>% 
  apply_cmonth(., ndays_thresh = 28) %>% 
  group_by(code_stn) %>% 
  nest() %>% 
  mutate(
    data = map(data, apply_cyears)
  )
```


O PSF é uma técnica de previsão para séries temporais univariadas e sua premissa é de que há um padrão de sequência na série analisada. O algoritmo [apresentou](https://journal.r-project.org/archive/2017/RJ-2017-021/RJ-2017-021.pdf) um desempenho superior, baseado somente na métrica RMSE, a modelos de séries temporais mais usados (autoregressivos e de suavização exponencial). Além disso, essa técnica de previsão possui o diferencial de usar as próprias previsões para retroalimentar a previsão para horizontes maiores. Iremos verificar seu desempenho para a série hidrológica dos postos da ONS. As observações do período de 1969-2016 serão usadas para treinamento do modelo, enquanto que os dois últimos anos (2017 e 2018) serão usados para avaliar seu desempenho.


```{r}
# Dados de treinamento (sem últimos dois anos)
train_qmly <- qnat_mly  %>% 
  mutate(data = map(data, get_traindt, yrs = 2))

# Dados para avaliação do PSF 
test_qmly <- qnat_mly %>% 
  mutate(qnat_obs = map(data,get_testdt)) %>% 
  select(code_stn,qnat_obs)
```


As previsões de vazão para os dois últimos anos de todos os postos da ONS foram feitas através da função `psf_reprod` para garantir a reprodutibilidade.

```{r}
# Vazão simulada (resultados reprodutíveis)
preds_qmly <- train_qmly %>% 
  mutate(qnat_pred = map(data,
                         ~psf_reprod(.x, n = 24, predict = TRUE)
                         )
         )

# Unindo predições e observações de cada posto
pobs_qmly <- inner_join(
  select(preds_qmly, -data),
  test_qmly,
  by = "code_stn"
) %>% 
  unnest(cols = -code_stn)

#groups(pobs_qmly)
```


A avaliação do desempenho do PSF para os últimos 24 meses considera as seguintes métricas estatísticas: erro médio absoluto (MAE), raiz quadrada do erro méio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.

```{r}
#groups(pobs_qmly)

aval_qmly <- pobs_qmly %>% #groups()
  #group_by(code_stn) %>%
  summarise(mKGE = KGE(sim = qnat_pred, obs = qnat_obs),
            mPBIAS = pbias(sim = qnat_pred, obs = qnat_obs),
            mNSE = NSE(sim = qnat_pred, obs = qnat_obs),
            RMSE = ModelMetrics::rmse(actual = qnat_obs,
                                  predicted = qnat_pred),
            mNRMSE = nrmse(sim = qnat_pred, obs = qnat_obs)
            ) %>% 
  arrange(-mKGE)

(aval_qmly)
```

Como KGE combina correlação, viés de variabilidade e da média, ele será priorizado nesta avaliação. Valores de $KGE > -0.41$ indicam um desempenho melhor que a média das observações.


```{r}
metrics_df <- aval_qmly %>%
  mutate(code_stn = factor(code_stn, levels = code_stn[order(mKGE)]),
         RMSE = NULL) %>%
  #filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )
aval_qmly %>%
  select(-RMSE) %>%
  filter(mKGE >= 0.3) %>%
  summarise(across(-code_stn, .fns = list(min = min), .names = "{.col}_{.fn}"))
  

metrics_df %>%
ggplot(aes(x = code_stn, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(metrics_df$metric)) + 
  theme(axis.text.x = )
```




```{r}
# Visualização das previsões do posto com melhor KGE
qnat_posto287 <- pobs_qmly %>% 
  sel_station(.,station = 287) %>% 
  select(date,qnat_obs,qnat_pred)

posto287_xts <- xts(qnat_posto287[,c("qnat_obs","qnat_pred")], 
                   order.by = as.Date(qnat_posto287[["date"]]))
forecast::autoplot(posto287_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```


## Aplicação do ensemble PSF


O PSF emprega o algoritmo de agrupamento  `kmeans` usando o método de Hartigan–Wong. Esta técnica gera resultados mais robustos ao variar aleatoriamente os valores iniciais dos centróides dos grupos. Portanto diferentes soluções são obtidas cada vez que a função é executada. Por esta razão, iremos fazer o  ensemble do PSF rodando cinco iterações e verificaremos se as previsões médias ou as previsões feitas com os parâmetros médios `k` e `w` são capazes de gerar melhores previsões. Inicialmente vamos armazenar as previsões e os parâmetros do modelo gerados em cada iteração utilizando a função `ensemble_psf`.


```{r}

# Modelos e predições resultantes de 5 iterações para cada posto
# start_time <- Sys.time()
# esb_qmly <- train_qmly %>%
#   mutate(
#     models = map(
#       data,
#       ~ ensemble_psf(.x, predict = FALSE)
#     ),
#     preds = map(data, ensemble_psf)
#   )
# end_time <- Sys.time() # ~9 minutos

# saveRDS(esb_qmly, file = here('output', 'esb_qmly.rds'))
# Carrega o modelo
esb_qmly <- readRDS(here("output", "esb_qmly.rds"))
```


A partir dos modelos gerados em cada iteração iremos extrair a média dos parâmetros críticos para o desempenho das previsões: `k` e `w`. Além disso, também calcularemos a média das previsões de cada iteração. A previsão utilizando o PSF sem o ensemble também foi incluída, visto que desejamos saber se a média das previsões ou se previsões feitas com os parâmetros médios irão aumentar a acúrácia do modelo.

```{r}
pobqmly_esb <- esb_qmly %>%
  mutate(
    # parâmetros k e w médios
    mparam_qmly = map(models, get_mpar),
    # previsões médias das iterações
    qnat_mpred = unlist(map(preds, get_mpred),
      recursive = FALSE
    ),
    qnat_pred = map(data,psf_reprod),
    # previsões usando k e w médios
    qnat_mpar = map(
      data, # previsões usando k e w médios
      ~ ensemble_mpar(.x, mparam_qmly)
    )
  ) %>%
  inner_join(.,
    test_qmly,
    by = "code_stn"
  ) %>%
  select(qnat_obs, qnat_mpred, qnat_mpar,qnat_pred) %>%
  unnest(cols = -code_stn)
```

Usaremos as seguintes métricas estatísticas para avaliar as previsões: erro médio absoluto (MAE), raiz quadrada do erro médio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.

```{r}
aval_esb <- pobqmly_esb %>%
  summarise(
    KGE_mpred = KGE(sim = qnat_mpred, obs = qnat_obs),
    KGE_mpar = KGE(sim = qnat_mpar, obs = qnat_obs),
    KGE_pred = KGE(sim = qnat_pred, obs = qnat_obs),
    mPBIAS = pbias(sim = qnat_mpred, obs = qnat_obs),
    mNRMSE = nrmse(sim = qnat_mpred, obs = qnat_obs),
    mNSE = mNSE(sim = qnat_mpred, obs = qnat_obs)
  ) %>%
  arrange(-KGE_pred)

(aval_esb)
```


Verificaremos qual modelo apresentou o KGE superior para um maior número de postos.

```{r}
metrics_esb <- aval_esb %>%
  select(code_stn, KGE_mpred, KGE_mpar, KGE_pred) %>%
  # filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )

bestKGE_esb <- metrics_esb %>%
  group_by(code_stn) %>%
  filter(valor >= 0.3) %>%
  slice(which.max(valor)) %>%
  ungroup() %>%
  count(metric)

(bestKGE_esb)
```

Aparentemente a média das previsões das cinco iterações forneceram o melhor resultado de acordo com a métrica KGE. No entanto, para avaliar se há vantagem em usar este modelo é importante conferir se a diferença foi significativa em relação as previsões feitas sem o ensemble.

```{r}
difb_esbKGE <- metrics_esb %>%
  group_by(code_stn) %>%
  filter(valor >= 0.3) %>%
  mutate(
    difb_KGE = max(valor) - min(valor)
  ) %>%
  slice(which.max(valor)) %>%
  arrange(-valor)

(difb_esbKGE)
```



## Validação cruzada aplicada ao posto 287


A validação cruzada é um método bastante utilizado não só para obter uma estimativa robusta do desempenho de um modelo, mas também para selecionar os melhores hiperparâmetros, isto é, os parâmetros que são definidos antes de treinar um modelo. Iremos aplicar este método para a série hidrológica do posto que obtivemos o melhor desempenho utilizando a técnica de previsão PSF. Além de obter uma estimativa mais robusta do desempenho do algoritmo para este posto, também iremos selecionar os valores ótimos para os parâmetros `k` e `w`.

```{r}
qnatmly_287 <- qnat_mly %>% 
  sel_station(.,287) %>% 
  unnest() %>% 
  ungroup() %>% 
  select(date,qnat_obs)
summary(qnatmly_287)
```


Iremos separar os dados em um conjunto de treinamento e outro de teste, tal como feito anteriormente, só que dessa vez iremos realizar previsões para um horizonte de 12 meses. A ideia é usar o conjunto de dados de teste para que após a validação cruzada possamos avaliar o desempenho das previsões utilizando os parâmetros ótimos selecionados.


```{r}
# Dados de treinamento sem o último ano
train287_qmly <- get_traindt(qnatmly_287,yrs = 1)
summary(train287_qmly)
# Dados para avaliação do PSF 
test287_qmly <- get_testdt(qnatmly_287,n = 12)
summary(test287_qmly)
```


Os dados de treinamento para cada iteração serão divididos em duas partições: treinamento e validação. Nessa forma de divisão teremos a partição de validação sempre a frente da partição de treinamento. A função `time_series_cv` do pacote `timetk` nos permite criar uma plano de amostragem começando com as observações mais atuais da série. A partir do parâmetro `assess` definimos que a partição da validação deverá ser formada de  12 meses de observações e o parâmetro `skip` fornece o número de meses que serão "pulados" em cada iteração ou divisão. Além disso, definimos o número de divisões através do parâmetro `slice_limit` e um número não fixo da janela foi escolhido através do parâmetro `cumulative`. Aumentando o número de divisões teremos uma avaliação mais robusta do modelo, porém há um maior custo computacional.

```{r}
resample_qmly287 <- time_series_cv(data = train287_qmly,
                                assess      = "12 months",
                                skip        = "36 months",
                                cumulative  = TRUE,
                                slice_limit = 15) 

# Visualização do plano de amostragem
#resample_qmly287 %>% 
#  plot_time_series_cv_plan(date,qnat_obs, .interactive = FALSE)
```



Na próxima etapa aplicaremos o PSF a todas as partições do conjunto de  treinamento e armazenaremos quais valores dos parâmetros `k` e `w` foram utilizados. Além disso, também iremos adicionar uma coluna com as previsões feitas a partir dos parâmetros médios.

```{r}
qmly287_slices <- resample_qmly287 %>%
  tk_time_series_cv_plan() %>%
  nest(date, qnat_obs) %>%
  pivot_wider(names_from = .key, values_from = data)

# Previsões usando um horizonte de 12 meses
cv287_qmly <- qmly287_slices %>%
  mutate(
    qnat_pred = map(
      training,
      ~ psf_reprod(.x, n = 12)
    ),
    model = map(
      training,
      ~ psf_reprod(.x, n = 12, predict = FALSE)
    ),
    cvparams = map(model, get_cvpar)
  )


# Média dos parâmetros k e w (2 e 3)
cvm_params <- round(Reduce("+", cv287_qmly[["cvparams"]])
/ length(cv287_qmly[["cvparams"]]), 0)

# Adicionando  coluna com as  prevs usando parâmetros médios
cv287_qmly <- cv287_qmly %>%
  mutate(qnatmpar_pred = map(
    training,
    ~ psf_cvparam(.x, n = 12, params = cvparams)
  ))
```



Iremos comparar o desempenho do modelo  com e sem a seleção dos parâmetros. 

```{r}
avalcv_m287 <- cv287_qmly %>%
  select(-c("model", "training", "cvparams")) %>%
  group_by(.id) %>%
  unnest() %>%
  summarise(
    KGEpred = KGE(sim = qnat_pred, obs = qnat_obs),
    KGEmpar = KGE(sim = qnatmpar_pred, obs = qnat_obs),
    PBIASmpar = pbias(sim = qnatmpar_pred, obs = qnat_obs),
    NRMSEmpar = nrmse(sim = qnatmpar_pred, obs = qnat_obs),
    NSEmpar = mNSE(sim = qnatmpar_pred, obs = qnat_obs)
  ) %>%
  ungroup() %>%
  summarise(
    KGEpred = mean(KGEpred),
    KGEmpar = mean(KGEmpar),
    PBIASmpar = mean(PBIASmpar),
    NRMSEmpar = mean(NRMSEmpar),
    NSEmpar = mean(NSEmpar)
  )
```



Enfim, iremos verificar o desempenho do modelo utilizando os parâmetros médios no conjunto de dado de testes.


```{r}
# Previsões feitas com os parâmetros médios
pcv287_mpar <- psf_cvparam(train287_qmly,
  n = 12,
  params = cvm_params
)
# Previsões sem a seleção dos parâmetros
preds287_qmly <- psf_reprod(train287_qmly, n = 12)

# Previsões e observações
pobs287cv_qmly <- mutate(test287_qmly,
  qnatcv_pred = NA,
  qnat_pred = NA,
  qnatcv_pred = replace(qnatcv_pred,
    values = pcv287_mpar
  ),
  qnat_pred = replace(qnat_pred,
    values = preds287_qmly
  )
)

avalcvmpar_287 <- pobs287cv_qmly %>%
  summarise(
    KGE = KGE(sim = qnat_pred, obs = qnat_obs),
    KGEcv = KGE(sim = qnatcv_pred, obs = qnat_obs)
  )
(avalcvmpar_287)
```

Observamos, baseado na métrica KGE, uma pequena melhora no modelo utilizando a seleção dos parâmetros ótimos.








