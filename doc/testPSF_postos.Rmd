---
title: "Aplicação do algoritmo PSF a séries de vazão naturalizada"
author: "Jerônimo Acker D'Ornellas"
date: "08/04/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
#rm(list = ls())
knitr::opts_chunk$set(
  #echo = FALSE,
  comment = "#>",
  collapse = TRUE
)
```

## Objetivo 

O objetivo do testePSF é realizar a aplicação do algoritmo PSF em séries hidrológicas e comparar o desempenho do algoritmo com outros métodos univariados amplamente usados para os dados das bacia hidrográficas da ONS.

## Pré-requisitos

Pacotes necessários:


```{r, message=FALSE}
if(!require(PSF)) install.packages("PSF")
if(!require(timetk)) remotes::install_github("business-science/timetk")
# tive que usar o tidyr do github
# por causa de erro no unnest()
#  Error: Input must be list of vectors
# remotes::install_github("tidyverse/tidyr")
pacotes <- c(
  "here",
  "usethis",
  "data.table",
  "HEobs",
  "PSF",
  "tidyverse",
  "lubridate",
  "fs",
  "checkmate",
  "xts",
  "hydroGOF",
  "ModelMetrics",
  "forecast",
  "timetk"
)
# Carregar os pacotes
easypackages::libraries(pacotes)
```

Scripts:

```{r}
source(here('R', 'load-data.R'))
source(here('R', 'utils.R'))
```


### Dados de vazão

Os dados importados de vazão devem ser regularmente espaçados no tempo. Esta adequação das séries diárias, se necessária, pode ser realizada com a função `complete_dates()` do pacote **`{lhmetools}`**. Assim assegura-se que todas estações possuam 1 observação por dia e sem datas faltantes.

```{r}
qnat_data <- qnat_dly_ons() %>%
  select(date, qnat, code_stn) %>%
  lhmetools::complete_dates(group = "code_stn")
glimpse(qnat_data)
```



## Aplicação do PSF para os principais postos da ONS

Observam-se dados faltantes na série, então selecionaremos através da função `apply_cmonth` somente os meses com pelo menos 28 observações válidas. Para robustez da avaliação consideraremos apenas anos que atendam ao critério de disponibilidade nos 12 meses do ano e verificamos se a série é múltipla de 12 como requisito da aplicação do PSF através da função `apply_cyears`.

```{r}
# Média mensal das observações de vazão para todos os postos
qnat_mly <- qnat_data %>% 
  apply_cmonth(., ndays_thresh = 28) %>% 
  group_by(code_stn) %>% 
  nest() %>% 
  mutate(
    data = map(data, apply_cyears)
  )
```


O PSF é uma técnica de previsão para séries temporais univariadas e sua premissa é de que há um padrão de sequência na série analisada. O algoritmo [apresentou](https://journal.r-project.org/archive/2017/RJ-2017-021/RJ-2017-021.pdf) um desempenho superior, baseado somente no RMSE, a modelos de séries temporais mais usados (autoregressivos e de suavização exponencial). Além disso, essa técnica de previsão possui o diferencial de usar as próprias previsões para retroalimentar a previsão para horizontes maiores. Dessa forma, iremos verificar o desempenho desta técnica para a série hidrológica dos postos da ONS. As observações do período de 1969-2016 serão usadas para treinamento do modelo, enquanto que os dois últimos anos (2017 e 2018) serão usados para avaliar seu desempenho.


```{r}
# Dados de treinamento (sem últimos dois anos)
train_qmly <- qnat_mly  %>% 
  mutate(data = map(data, get_traindt, yrs = 2))

# Dados para avaliação do PSF 
test_qmly <- qnat_mly %>% 
  mutate(qnat_obs = map(data,get_testdt)) %>% 
  select(code_stn,qnat_obs)
```


As previsões de vazão para os dois últimos anos de todos os postos da ONS foram feitas através da função `psf_reprod` que assegura, ao definir uma semente, a reprodutibilidade dos resultados.

```{r}
# Vazão simulada (resultados reprodutíveis)
preds_qmly <- train_qmly %>% 
  mutate(qnat_pred = map(data,
                         ~psf_reprod(.x, n = 24, predict = TRUE)
                         )
         )

# Unindo predições e observações de cada posto
pobs_qmly <- inner_join(
  select(preds_qmly, -data),
  test_qmly,
  by = "code_stn"
) %>% 
  unnest(cols = -code_stn)

#groups(pobs_qmly)
```


A avaliação do desempenho do PSF para os últimos 24 meses considera as seguintes métricas estatísticas: erro médio absoluto (MAE), raiz quadrada do erro méio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.

```{r}
#groups(pobs_qmly)

aval_qmly <- pobs_qmly %>% #groups()
  #group_by(code_stn) %>%
  summarise(mKGE = KGE(sim = qnat_pred, obs = qnat_obs),
            mPBIAS = pbias(sim = qnat_pred, obs = qnat_obs),
            mNSE = NSE(sim = qnat_pred, obs = qnat_obs),
            RMSE = ModelMetrics::rmse(actual = qnat_obs,
                                  predicted = qnat_pred),
            mNRMSE = nrmse(sim = qnat_pred, obs = qnat_obs)
            ) %>% 
  arrange(-mKGE)

aval_qmly
```

Como KGE combina correlação, viés de variabilidade e da média, ele será priorizado nesta avaliação. Valores de $KGE > -0.41$ indicam um desempenho melhor que a média das observações.


```{r}
metrics_df <- aval_qmly %>%
  mutate(code_stn = factor(code_stn, levels = code_stn[order(mKGE)]),
         RMSE = NULL) %>%
  #filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )
aval_qmly %>%
  select(-RMSE) %>%
  filter(mKGE >= 0.3) %>%
  summarise(across(-code_stn, .fns = list(min = min), .names = "{.col}_{.fn}"))
  

metrics_df %>%
ggplot(aes(x = code_stn, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(metrics_df$metric)) + 
  theme(axis.text.x = )
```


## Aplicação do ensemble PSF


O PSF emprega o algoritmo de agrupamento  `kmeans` usando o método de Hartigan–Wong. Esta técnica gera resultados mais robustos ao variar aleatoriamente os valores iniciais dos centróides dos grupos. Portanto diferentes soluções são obtidas cada vez que a função é executada. Por esta razão, iremos empregar um



```{r}
# Modelos e predições resultantes de 5 iterações para cada posto
# start_time <- Sys.time()
# esb_qmly <- train_qmly %>%
#   mutate(
#     models = map(
#       data,
#       ~ ensemble_psf(.x, predict = FALSE)
#     ),
#     preds = map(data, ensemble_psf)
#   )
# end_time <- Sys.time() # ~9 minutos

# saveRDS(esb_qmly, file = here('output', 'esb_qmly.rds'))
# Carrega o modelo
esb_qmly <- readRDS(here("output", "esb_qmly.rds"))

pobqmly_esb <- esb_qmly %>%
  mutate(
    mparam_qmly = map(models, get_mpar),
    # parâmetros k e w médios
    qnat_mpred = unlist(map(preds, get_mpred),
      recursive = FALSE
    ),
    # predições médias das iter
    qnat_mpar = map(
      data, # predições usando k e w médios
      ~ ensemble_mpar(.x, mparam_qmly)
    )
  ) %>%
  inner_join(.,
    test_qmly,
    by = "code_stn"
  ) %>%
  select(qnat_obs, qnat_mpred, qnat_mpar) %>%
  unnest(cols = -code_stn)


aval_ensemble <- pobqmly_esb %>%
  summarise(
    KGE_mpred = KGE(sim = qnat_mpred, obs = qnat_obs),
    KGE_mpar = KGE(sim = qnat_mpar, obs = qnat_obs),
    mPBIAS = pbias(sim = qnat_mpred, obs = qnat_obs),
    mNRMSE = nrmse(sim = qnat_mpred, obs = qnat_obs),
    mNSE = mNSE(sim = qnat_mpred, obs = qnat_obs)
  ) %>%
  arrange(-KGE_mpred)

(aval_ensemble)
```

Gráfico do posto com melhor KGE


```{r}
# Gráfico 
qnat_posto287 <- pobqmly_esb %>% 
  sel_station(.,station = 287) %>% 
  select(date,qnat_obs,qnat_mpred)# melhor KGE usando qnat_mpred

posto287_xts <- xts(qnat_posto287[,c("qnat_obs","qnat_mpred")], 
                   order.by = as.Date(qnat_posto287[["date"]]))
forecast::autoplot(posto287_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```


## Validação cruzada aplicada ao posto 287

```{r}
qnatmly_287 <- qnat_mly %>% 
  sel_station(.,287) %>% 
  unnest() %>% 
  ungroup() %>% 
  select(date,qnat_obs)
summary(qnatmly_287)

# Dados de treinamento sem o último ano
train287_qmly <- get_traindt(qnatmly_287,yrs = 1)
summary(train287_qmly)

# Dados para avaliação do PSF 
test287_qmly <- get_testdt(qnatmly_287,n = 12)
summary(test287_qmly)
```

Explique o que está sendo feito ... 

> muito interessante o pacote ModelTime! Show este timetk, não conhecia! Vamos dar uma olhada nisso posteriormente.

```{r}
resample_spec <- time_series_cv(data = qnatmly_287,
                                assess      = "12 months",# df teste inicial
                                skip        = "12 months",
                                cumulative  = TRUE,
                                slice_limit = 5) 


qmly287_slices <- resample_spec %>% 
  tk_time_series_cv_plan() %>%
  nest(date, qnat_obs) %>% 
  pivot_wider(names_from = .key,values_from = data)

# Predições usando um horizonte de 12 meses
cv287_qmly <- qmly287_slices %>% 
  mutate(
    qnat_pred = map(training,
                    ~psf_reprod(.x, n = 12)),
    model = map(training,
                #~psf_reprod(.x,n = 12, ret = "model")
                ~psf_reprod(.x, n = 12, predict = FALSE)
                ),
    cvparams = map(model,get_cvpar)
  )

# Parâmetros k e w
# tinha esquecido que são numeros discretos, melhor usar a moda!
# Mas analise os resultados e veja se eles fazem sentido

cvm_params <- round(Reduce("+",cv287_qmly[["cvparams"]])
                    /length(cv287_qmly[["cvparams"]]),0)
# cv287_qmly[["cvparams"]]
# k  w
# 2  4?

# usar a MODA!
moda <- function(x){
  which.max(tabulate(x))
}

cvm_params <- cv287_qmly[["cvparams"]] %>%
  map_dfr(~.x) %>%
  summarise(across(c(k, w), moda))
#cvm_params
# 2  5

# Qual o propósito disso? não teria que aplicar ao cv287_qmly[["testing"]]?
preds287_qmly <- psf_cvparam(train287_qmly,
                             n = 12,
                             params = cvm_params
                             )

pobs287_qmly <- mutate(train287_qmly,
                  qnat_pred = NA,
                  qnat_pred = replace(qnat_pred,
                    values = preds287_qmly
                  )
) 

avalcv_287 <- pobs287_qmly %>% 
  summarise(KGE = KGE(sim = qnat_pred, obs = qnat_obs)
  ) 
(avalcv_287)
```


