---
title: "Aplicação do algoritmo PSF a séries de vazão naturalizada"
author: "Jerônimo Acker D'Ornellas"
date: "08/04/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
#rm(list = ls())
knitr::opts_chunk$set(
  #echo = FALSE,
  comment = "#>",
  collapse = TRUE
)
```

## Objetivo 

O objetivo do testePSF é realizar a aplicação do algoritmo PSF em séries hidrológicas e comparar o desempenho do algoritmo com outros métodos univariados amplamente usados para os dados da bacia hidrográfica do posto ONS de código 74.

## Pré-requisitos

Pacotes necessários:


```{r, message=FALSE}
if(!require(PSF)) remotes::install_github("neerajdhanraj/PSF")
if(!require(timetk)) remotes::install_github("business-science/timetk")
# tive que usar o tidyr do github
# por causa de erro no unnest()
#  Error: Input must be list of vectors
# remotes::install_github("tidyverse/tidyr")
pacotes <- c(
  "here",
  "usethis",
  "data.table",
  "HEobs",
  "PSF",
  "tidyverse",
  "lubridate",
  "fs",
  "checkmate",
  "xts",
  "hydroGOF",
  "ModelMetrics",
  "forecast",
  "timetk"
)
# Carregar os pacotes
easypackages::libraries(pacotes)
```

Scripts:

```{r}
source(here('R', 'load-data.R'))
source(here('R', 'utils.R'))
```


### Dados de vazão

Os dados importados de vazão devem ser regularmente espaçados no tempo. Esta adequação das séries diárias, se necessária, pode ser realizada com a função `complete_dates()` do pacote **`{lhmetools}`**. Assim assegura-se que todas estações possuam 1 observação por dia e sem datas faltantes.

```{r}
qnat_data <- qnat_dly_ons() %>%
  select(date, qnat, code_stn) %>%
  lhmetools::complete_dates(group = "code_stn")
glimpse(qnat_data)
```

Os dados importados precisam filtrados para o posto de interesse: posto 74 da ONS (G. B. Munhoz).

```{r}
posto <- 74
qnat_posto <- qnat_data %>% 
  dplyr::filter(code_stn == posto)
glimpse(qnat_posto)
```


Observam-se dados faltantes na série do posto 74, então selecionaremos somente os meses com pelo menos 28 observações válidas e anos completos.

```{r}
# Seleciona observações com pelo menos 28 observações válidas no mês
qnat_posto_mly <- qnat_posto %>% 
  dplyr::group_by(date = floor_date(date, "month"), code_stn) %>% 
  dplyr::summarise(
    qnat_obs = mean_wise(qnat), 
    valid = nvalid(qnat), 
    N = n(),
    .groups = "drop"
  ) %>%
  dplyr::filter(valid >= 28) 

# check
#str(qnat_posto_mly)
# qnat_posto_mly %>% 
#   lhmetools::complete_dates(group = "code_stn", time_step = # "month") %>%
#   str()
```

Para robustez da avaliação consideraremos apenas anos que atendam ao critério de disponibilidade nos 12 meses do ano e verificamos se a série é múltipla de 12 como requisito da de aplicação do PSF.

```{r}
# Anos completos
anos_comp <- qnat_posto_mly %>%
  group_by(ano = lubridate::year(date)) %>%
  tally() %>%
  filter(n == 12) %>%
  pull(ano) 
# Usa apenas as observações dos anos completos
qnat_posto_mly <- qnat_posto_mly %>%
  filter(lubridate::year(date) %in% anos_comp)
# check
#qnat_posto_mly %>%
#  filter(valid != N)
# Seleciona apenas a data e as observações de vazão 
qnat_posto_mly <- qnat_posto_mly %>%
  select(date, qnat_obs)

# check
head(qnat_posto_mly)
tail(qnat_posto_mly)
stopifnot(nrow(qnat_posto_mly) %% 12 == 0)
#nrow(qnat_posto_mly) %/% 12
```


### Aplicação do algoritmo PSF

Explicar o que e porquê está sendo feito isso. Para testar o PSF é necessário ... período de treino e teste ... 2 anos ...


```{r}
#PSF:::convert_datatype(data = qnat_posto_mly["qnat_obs"])
# dados de treino: 2017 e 2018
(leave_out <- tail(anos_comp, n = 2))
data_train <- qnat_posto_mly %>%
  filter(!lubridate::year(date) %in% leave_out)
```

O PSF requer a especificação dos parâmetros ... k, w, cycle, pq estes valores ...

```{r}
# Treinamento do modelo
set.seed(123)
modelo_munhoz <- psf(
  data_train[["qnat_obs"]],
  #n.ahead = 12 * length(leave_out),
  #k = 2:20,
  k = 3:20,
  w = 1:10,
  cycle = 12
)
```

Com o modelo treinado podemos prever para o período de teste usando: 

```{r}
# teste: previsão de vazão para 2017 e 2018
pred_munhoz <- predict(modelo_munhoz,
                       n.ahead = 12 * length(leave_out)
                       )
# Comparação dos valores observados e previstos para os dois últimos anos
plot(modelo_munhoz, pred_munhoz)
```


As previsões do PSF podem ser adicionadas aos dados originais.

```{r}
inds <- (nrow(data_train) + 1):(nrow(data_train) + (12 * length(leave_out)))
nrow(qnat_posto_mly) == max(inds)

qnat_posto_mly_pred <- mutate(qnat_posto_mly,
  qnat_pred = NA,
  qnat_pred = replace(qnat_pred,
    list = inds,
    values = pred_munhoz
  )
)
tail(qnat_posto_mly_pred, 12 * length(leave_out) + 1)
```



```{r}
df <- qnat_posto_mly_pred[inds,]
df_ts <- xts(df[,-1], order.by = as.Date(df[["date"]]))
forecast::autoplot(df_ts, facets = FALSE) + 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```


## Avaliação


A avaliação do desempenho do PSF para os últimos 24 meses considera as seguintes métricas estatísticas: erro médio absoluto (MAE), raiz quadrada do erro méio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.

```{r}
# seleciona índices de interesse
# ctrl+alt+c
pos_stat_inds <- c(2, 4:6, 9, 17, 19:20) 

stat_eval <- hydroGOF::gof(
  sim = df_ts$qnat_pred, 
  obs = df_ts$qnat_obs)[pos_stat_inds,]
stat_eval
#names(stat_eval)
```

Como KGE combina correlação, viés de variabilidade e da média, ele será priorizado nesta avaliação. Valores de $KGE > -0.41$ indicam um desempenho melhor que a média das observações.

O PSF emprega o algoritmo de agrupamento  `kmeans` usando o método de Hartigan–Wong. Esta técnica gera resultados mais robustos ao variar aleatoriamente os valores iniciais dos centróides dos grupos.
Portanto diferente soluções são obtidas cada vez que a função é executada. Por esta razão, foram feitas 10 iterações com diferentes sementes e a média do [KGE](https://www.rdocumentation.org/packages/hydroGOF/versions/0.4-0/topics/KGE) foi usada para obter avaliar o desempenho das predições feitas pelo PSF. Somente os parâmetros `k` (número de grupos) e `w` (tamanho da janela) foram variados.

> Como comentado no [livro](https://books.google.com/books?id=7l0sCQAAQBAJ&pg=PA163&lpg=PA163&dq=number%20of%20initial%20configurations%20kmena&source=bl&ots=n0nhiF0BwY&sig=1fBoasnqNNnZcyc1PhfhLJMSFfA&hl=en&sa=X&ved=0ahUKEwje4_O7habVAhXExFQKHSvqD60Q6AEIVDAH#v=onepage&q=number%20of%20initial%20configurations%20kmena&f=false) as iterações podem ser feitas com o parâmetro `nstart`diretamente na função `stats::kmeans()` e recomendam `nstart = 25`. A função retornará o melhor resultado. Porque ele não usou isso?

```{r}
obs_74 <- df$qnat_obs
niter <- 10
metricas74 <- rep(NA, niter)

for (i in 1:niter) {
  # i = 1

  # PSF
  psf_model <- psf(data_train[["qnat_obs"]],
    k = 3:20,
    w = 1:10,
    cycle = 12
  )
  preds <- predict(psf_model,
    n.ahead = 12 * length(leave_out)
  )
  # Erro do PSF
  # metricasx[i] <-  sqrt(mean((df_ts$qnat_obs- preds)^2))
  metricas74[i] <- KGE(
    sim = preds,
    obs = obs_74
  )
}

(KGE74_psf <- mean(metricas74))
```

> Daqui para baixo sugiro colocar em outro RMD.

## Aplicação do PSF para os principais postos da ONS


```{r}
# Média mensal das observações de vazão para todos os postos
qnat_mly <- qnat_data %>% 
  apply_cmonth(., ndays_thresh = 28) %>% 
  group_by(code_stn) %>% 
  nest() %>% 
  mutate(
    data = map(data, apply_cyears)
  )

# Dados de treinamento (sem últimos dois anos)
train_qmly <- qnat_mly  %>% 
  mutate(data = map(data, get_traindt, yrs = 2))

# Dados para avaliação do PSF 
test_qmly <- qnat_mly %>% 
  mutate(qnat_obs = map(data,get_testdt)) %>% 
  select(code_stn,qnat_obs)

# Vazão simulada (resultados reprodutíveis)
preds_qmly <- train_qmly %>% 
  mutate(qnat_pred = map(data,
                         ~psf_reprod(.x, n = 24, predict = TRUE)
                         )
         )
```



```{r}
# Predições e observações
pobs_qmly <- inner_join(
  select(preds_qmly, -data),
  test_qmly,
  by = "code_stn"
) %>% 
  unnest(cols = -code_stn)

#groups(pobs_qmly)

aval_qmly <- pobs_qmly %>% #groups()
  #group_by(code_stn) %>%
  summarise(mKGE = KGE(sim = qnat_pred, obs = qnat_obs),
            mPBIAS = pbias(sim = qnat_pred, obs = qnat_obs),
            mNSE = NSE(sim = qnat_pred, obs = qnat_obs),
            RMSE = ModelMetrics::rmse(actual = qnat_obs,
                                  predicted = qnat_pred),
            mNRMSE = nrmse(sim = qnat_pred, obs = qnat_obs)
            ) %>% 
  arrange(-mKGE)

aval_qmly
```

```{r}
metrics_df <- aval_qmly %>%
  mutate(code_stn = factor(code_stn, levels = code_stn[order(mKGE)]),
         RMSE = NULL) %>%
  #filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )
aval_qmly %>%
  select(-RMSE) %>%
  filter(mKGE >= 0.3) %>%
  summarise(across(-code_stn, .fns = list(min = min), .names = "{.col}_{.fn}"))
  

metrics_df %>%
ggplot(aes(x = code_stn, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(metrics_df$metric)) + 
  theme(axis.text.x = )
```


## Aplicação do ensemble PSF


```{r}
# Modelos e predições resultantes de 5 iterações para cada posto

# start_time <- Sys.time()
# esb_qmly <- train_qmly %>% 
#   mutate(
#     models = map(data,ensemble_models),
#     preds = map(data,ensemble_preds)
#   )
# end_time <- Sys.time() # Demorou 8.775542 mins

#saveRDS(ensemble_postos_all, file = here('output', 'ensemble_all.rds'))
esb_qmly <- readRDS(here('doc', 'ensemble_all.rds'))

# Predições e observações do ensemble
pobqmly_esb <- esb_qmly %>% 
  mutate(
    mparam_qmly = map(models,get_mpar), # parâmetros k e w médios
    qnat_mpred = unlist(map(preds,get_mpred),
                        recursive = FALSE), # predições médias das iter
    qnat_mpar = map(train_data, # predições usando k e w médios
                    ~ensemble_mpar(.x,mparam_qmly))
  ) %>% 
   inner_join(.,
             test_qmly,
             by = "code_stn") %>% 
  select(qnat_obs,qnat_mpred,qnat_mpar) %>% 
  unnest(cols = -code_stn) 



aval_ensemble <- pobqmly_esb %>% 
  summarise(KGE_mpred = KGE(sim = qnat_mpred, obs = qnat_obs),
            KGE_mpar = KGE(sim = qnat_mpar, obs = qnat_obs),
            mPBIAS = pbias(sim = qnat_mpred, obs = qnat_obs),
            mNRMSE = nrmse(sim = qnat_mpred, obs = qnat_obs),
            mNSE = mNSE(sim = qnat_mpred, obs = qnat_obs)
  ) %>% 
  arrange(-KGE_mpred)

(aval_ensemble)
```

Gráfico do posto com melhor KGE


```{r}
# Gráfico 
qnat_posto287 <- pobqmly_esb %>% 
  sel_station(.,station = 287) %>% 
  select(date,qnat_obs,qnat_mpred)# melhor KGE usando qnat_mpred

posto287_xts <- xts(qnat_posto287[,c("qnat_obs","qnat_mpred")], 
                   order.by = as.Date(qnat_posto287[["date"]]))
forecast::autoplot(posto287_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```


## Validação cruzada aplicada ao posto 287

```{r}
qnatmly_287 <- qnat_mly %>% 
  sel_station(.,287) %>% 
  unnest() %>% 
  ungroup() %>% 
  select(date,qnat_obs)
summary(qnatmly_287)

# Dados de treinamento sem o último ano
train287_qmly <- get_traindt(qnatmly_287,yrs = 1)
summary(train287_qmly)

# Dados para avaliação do PSF 
test287_qmly <- get_testdt(qnatmly_287,n = 12)
summary(test287_qmly)
```

Explique o que está sendo feito ... 

> muito interessante o pacote ModelTime! Show este timetk, não conhecia! Vamos dar uma olhada nisso posteriormente.

```{r}
resample_spec <- time_series_cv(data = qnatmly_287,
                                assess      = "12 months",# df teste inicial
                                skip        = "12 months",
                                cumulative  = TRUE,
                                slice_limit = 5) 


qmly287_slices <- resample_spec %>% 
  tk_time_series_cv_plan() %>%
  nest(date, qnat_obs) %>% 
  pivot_wider(names_from = .key,values_from = data)

# Predições usando um horizonte de 12 meses
cv287_qmly <- qmly287_slices %>% 
  mutate(
    qnat_pred = map(training,
                    ~psf_reprod(.x, n = 12)),
    model = map(training,
                #~psf_reprod(.x,n = 12, ret = "model")
                ~psf_reprod(.x, n = 12, predict = FALSE)
                ),
    cvparams = map(model,get_cvpar)
  )

# Parâmetros k e w
# tinha esquecido que são numeros discretos, melhor usar a moda!
# Mas analise os resultados e veja se eles fazem sentido

cvm_params <- round(Reduce("+",cv287_qmly[["cvparams"]])
                    /length(cv287_qmly[["cvparams"]]),0)
# cv287_qmly[["cvparams"]]
# k  w
# 2  4?

# usar a MODA!
moda <- function(x){
  which.max(tabulate(x))
}

cvm_params <- cv287_qmly[["cvparams"]] %>%
  map_dfr(~.x) %>%
  summarise(across(c(k, w), moda))
#cvm_params
# 2  5

# Qual o propósito disso? não teria que aplicar ao cv287_qmly[["testing"]]?
preds287_qmly <- psf_cvparam(train287_qmly,
                             n = 12,
                             params = cvm_params
                             )

pobs287_qmly <- mutate(train287_qmly,
                  qnat_pred = NA,
                  qnat_pred = replace(qnat_pred,
                    values = preds287_qmly
                  )
) 

avalcv_287 <- pobs287_qmly %>% 
  summarise(KGE = KGE(sim = qnat_pred, obs = qnat_obs)
  ) 
(avalcv_287)
```


