---
title: "Aplicação do algoritmo PSF a séries de vazão naturalizada"
author: "Jerônimo Acker D'Ornellas"
date: "08/04/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---


```{r setup, include=FALSE}
#rm(list = ls())
knitr::opts_chunk$set(
  #echo = FALSE,
  comment = "#>",
  collapse = TRUE
)
```

## Objetivo 

O objetivo do testePSF é realizar a aplicação do algoritmo PSF em séries hidrológicas e comparar o desempenho do algoritmo com outros métodos univariados amplamente usados para os dados das bacia hidrográficas da ONS. 

## Pré-requisitos

Pacotes necessários:


```{r, message=FALSE}
if(!require(PSF)) install.packages("PSF")
if(!require(timetk)) remotes::install_github("business-science/timetk")
# tive que usar o tidyr do github
# por causa de erro no unnest()
#  Error: Input must be list of vectors
# remotes::install_github("tidyverse/tidyr")
pacotes <- c(
  "here",
  "usethis",
  "data.table",
  "HEobs",
  "PSF",
  "tidyverse",
  "lubridate",
  "fs",
  "checkmate",
  "xts",
  "hydroGOF",
  "ModelMetrics",
  "forecast",
  "timetk"
)
# Carregar os pacotes
easypackages::libraries(pacotes)
```

Scripts:

```{r}
source(here('R', 'load-data.R'))
source(here('R', 'utils.R'))
```


### Dados de vazão

Os dados importados de vazão devem ser regularmente espaçados no tempo. Esta adequação das séries diárias, se necessária, pode ser realizada com a função `complete_dates()` do pacote **`{lhmetools}`**. Assim assegura-se que todas estações possuam 1 observação por dia e sem datas faltantes.

```{r}
qnat_data <- qnat_dly_ons() %>%
  select(date, qnat, code_stn) %>%
  lhmetools::complete_dates(group = "code_stn")
glimpse(qnat_data)
```


Observam-se dados faltantes na série, então selecionaremos através da função `apply_cmonth` somente os meses com pelo menos 28 observações válidas. Para robustez da avaliação consideraremos apenas anos que atendam ao critério de disponibilidade nos 12 meses do ano e verificamos se a série é múltipla de 12 como requisito da aplicação do PSF através da função `apply_cyears`.

```{r}
# Média mensal das observações de vazão para todos os postos
qnat_mly <- qnat_data %>% 
  apply_cmonth(., ndays_thresh = 28) %>% 
  group_by(code_stn) %>% 
  nest() %>% 
  mutate(
    data = map(data, apply_cyears)
  )
```


O PSF é uma técnica de previsão para séries temporais univariadas e sua premissa é de que há um padrão de sequência na série analisada. O algoritmo [apresentou](https://journal.r-project.org/archive/2017/RJ-2017-021/RJ-2017-021.pdf) um desempenho superior, baseado somente na métrica RMSE, a modelos de séries temporais mais usados (autoregressivos e de suavização exponencial). Além disso, essa técnica de previsão possui o diferencial de usar as próprias previsões para retroalimentar a previsão para horizontes maiores. Iremos verificar seu desempenho para as séries hidrológicas dos postos da ONS. As observações do período de 1969-2016 serão usadas para treinamento do modelo, enquanto que os dois últimos anos (2017 e 2018) serão usados para avaliar seu desempenho.


```{r}
# Dados de treinamento (sem últimos dois anos)
train_qmly <- qnat_mly  %>% 
  mutate(data = map(data, get_traindt, yrs = 2))

# Dados para avaliação do PSF 
test_qmly <- qnat_mly %>% 
  mutate(qnat_obs = map(data,get_testdt)) %>% 
  select(code_stn,qnat_obs)
```



A função `psf_reprod` garante a reprodutibilidade dos resultados.

```{r}
# Vazão prevista 
prevs_qmly <- train_qmly %>% 
  mutate(qnat_pred = map(data,
                         ~psf_reprod(.x, n = 24, predict = TRUE)
                         )
         )

# Unindo previsões e observações de cada posto
pobs_qmly <- inner_join(
  select(prevs_qmly, -data),
  test_qmly,
  by = "code_stn"
) %>% 
  unnest(cols = -code_stn)

#groups(pobs_qmly)
```


A avaliação do desempenho do PSF para os últimos 24 meses considera as seguintes métricas estatísticas: erro médio absoluto (MAE), raiz quadrada do erro méio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.

```{r}
# groups(pobs_qmly)

aval_qmly <- pobs_qmly %>% # groups()
  # group_by(code_stn) %>%
  summarise(
    mKGE = KGE(sim = qnat_pred, obs = qnat_obs),
    mPBIAS = pbias(sim = qnat_pred, obs = qnat_obs),
    mNSE = NSE(sim = qnat_pred, obs = qnat_obs),
    RMSE = ModelMetrics::rmse(
      actual = qnat_obs,
      predicted = qnat_pred
    ),
    mNRMSE = nrmse(sim = qnat_pred, obs = qnat_obs)
  ) %>%
  arrange(-mKGE)

(aval_qmly)
```

Como KGE combina correlação, viés de variabilidade e da média, ele será priorizado nesta avaliação. Valores de $KGE > -0.41$ indicam um desempenho melhor que a média das observações.


```{r}
metrics_df <- aval_qmly %>%
  mutate(code_stn = factor(code_stn, levels = code_stn[order(mKGE)]),
         RMSE = NULL) %>%
  #filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )
aval_qmly %>%
  select(-RMSE) %>%
  filter(mKGE >= 0.3) %>%
  summarise(across(-code_stn, .fns = list(min = min), .names = "{.col}_{.fn}"))
  

metrics_df %>%
ggplot(aes(x = code_stn, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(metrics_df$metric)) + 
  theme(axis.text.x = )
```

Visualização da melhor previsão baseado na métrica KGE.

```{r}
qnat_posto287 <- pobs_qmly %>% 
  sel_station(.,station = 287) %>% 
  select(date,qnat_obs,qnat_pred)

posto287_xts <- xts(qnat_posto287[,c("qnat_obs","qnat_pred")], 
                   order.by = as.Date(qnat_posto287[["date"]]))
forecast::autoplot(posto287_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```


## Aplicação do ensemble PSF


O pacote PSF emprega o algoritmo de agrupamento  `kmeans` usando o método de Hartigan–Wong. Esta técnica gera resultados mais robustos ao variar aleatoriamente os valores iniciais dos centróides dos grupos. Portanto diferentes soluções são obtidas cada vez que a função é executada. Iremos fazer o ensemble do PSF rodando cinco iterações e verificaremos se as previsões médias e as previsões feitas com as modas dos parâmetros `k` e `w` dos modelos são capazes de gerar melhores resultados.


A função `ensemble_psf` é usada para gerar os modelos e suas previsões.

```{r}

# Modelos e predições resultantes de 5 iterações para cada posto
# start_time <- Sys.time()
# esb_qmly <- train_qmly %>%
#   mutate(
#     models = map(
#       data,
#       ~ ensemble_psf(.x, predict = FALSE)
#     ),
#     preds = map(data, ensemble_psf)
#   )
# end_time <- Sys.time() # ~9 minutos

# saveRDS(esb_qmly, file = here('output', 'esb_qmly.rds'))
# Carrega o modelo
esb_qmly <- readRDS(here("output", "esb_qmly.rds"))
```


A partir dos modelos gerados em cada iteração iremos extrair a moda dos parâmetros críticos para o desempenho das previsões: `k` e `w`. Além disso, calcularemos a média das previsões de cada modelo. A previsão utilizando o PSF sem o ensemble foi incluída para comparação.

```{r}
pobqmly_esb <- esb_qmly %>%
  mutate(
    # moda dos parâmetros k e w 
    modparam_qmly = map(models, get_modpar),
    # previsões médias das iterações
    qnat_mpred = unlist(map(preds, get_mpred),
      recursive = FALSE
    ),
    qnat_pred = map(data,psf_reprod),
    # previsões usando k e w médios
    qnat_modpar = map(
      data, # previsões usando k e w médios
      ~ ensemble_mpar(.x, modparam_qmly)
    )
  ) %>%
  inner_join(.,
    test_qmly,
    by = "code_stn"
  ) %>%
  select(qnat_obs, qnat_mpred, qnat_modpar,qnat_pred) %>%
  unnest(cols = -code_stn)
```

Usaremos as seguintes métricas estatísticas para avaliar as previsões: erro médio absoluto (MAE), raiz quadrada do erro médio (RMSE), o RMSE normalizado pelo desvio padrão da observação (NRMSE %), O viés relativo (PBIAS %), o coeficiente de Nash-Sutcliffe, coeficiente de determinação (R^2^), o coeficiente de Kling-Gupta Efficiency (KGE) e VE.


```{r}
aval_esb <- pobqmly_esb %>%
  summarise(
    KGE_mpred = KGE(sim = qnat_mpred, obs = qnat_obs),
    KGE_modpar = KGE(sim = qnat_modpar, obs = qnat_obs),
    KGE_pred = KGE(sim = qnat_pred, obs = qnat_obs),
    mPBIAS = pbias(sim = qnat_mpred, obs = qnat_obs),
    mNRMSE = nrmse(sim = qnat_mpred, obs = qnat_obs),
    mNSE = mNSE(sim = qnat_mpred, obs = qnat_obs)
  ) %>%
  arrange(-KGE_pred)

(aval_esb)
```


Verificaremos qual modelo apresentou o KGE superior para um maior número de postos.

```{r}
metrics_esb <- aval_esb %>%
  select(code_stn, KGE_mpred, KGE_modpar, KGE_pred) %>%
  mutate(code_stn = factor(code_stn, levels = code_stn[order(KGE_mpred)])) %>% 
  # filter(mKGE >= 0.3 | mNSE >= 0.5) %>%
  pivot_longer(
    cols = -c(code_stn),
    names_to = "metric",
    values_to = "valor"
  )

metrics_esb %>%
ggplot(aes(x = code_stn, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(metrics_esb$metric)) + 
  theme(axis.text.x = )
```


```{r}
bestKGE_esb <- metrics_esb %>%
  group_by(code_stn) %>%
  filter(valor >= 0.3) %>%
  slice(which.max(valor)) %>%
  ungroup() %>%
  count(metric)

(bestKGE_esb)
```


A média das previsões das cinco iterações forneceram o melhor resultado de acordo com métrica KGE. No entanto, para avaliar se há vantagem em usar este modelo vamos verificar se a diferença foi significativa em relação as previsões feitas sem o ensemble.

```{r}
difb_esbKGE <- metrics_esb %>%
  group_by(code_stn) %>%
  filter(valor >= 0.3) %>%
  mutate(
    difb_KGE = max(valor) - min(valor)
  ) %>%
  slice(which.max(valor)) %>%
  arrange(-valor)

(difb_esbKGE)
(summary(difb_esbKGE$difb_KGE))
```



## Validação cruzada aplicada ao posto 287


A validação cruzada é um método bastante utilizado não só para obter uma estimativa robusta do desempenho de um modelo, mas também para selecionar os melhores hiperparâmetros, isto é, os parâmetros que são definidos antes de treinar um modelo. Iremos aplicar este método para a série hidrológica do posto que obtivemos o melhor desempenho utilizando a técnica de previsão PSF. Além de obter uma estimativa mais robusta do desempenho do algoritmo para este posto, também iremos selecionar os valores ótimos para os parâmetros `k` e `w`.

```{r}
qnatmly_287 <- qnat_mly %>% 
  sel_station(.,287) %>% 
  unnest() %>% 
  ungroup() %>% 
  select(date,qnat_obs)
summary(qnatmly_287)
```


Iremos separar os dados em um conjunto de treinamento e outro de teste, tal como feito anteriormente, só que dessa vez realizaremos previsões para um horizonte de 12 meses. A ideia é usar o conjunto de dados de teste após a validação cruzada para avaliar o desempenho das previsões utilizando os parâmetros selecionados.


```{r}
# Dados de treinamento sem o último ano
train287_qmly <- get_traindt(qnatmly_287,yrs = 1)
summary(train287_qmly)
# Dados para avaliação do PSF 
test287_qmly <- get_testdt(qnatmly_287,n = 12)
summary(test287_qmly)
```


Os dados de treinamento serão divididos em duas partições: treinamento e validação. Nessa forma de divisão teremos a partição de validação sempre a frente da partição de treinamento. A função `time_series_cv` do pacote `timetk` nos permite criar uma plano de amostragem começando com as observações mais atuais da série. A partir do parâmetro `assess` definimos que a partição da validação deverá ser formada de  12 meses de observações e o parâmetro `skip` fornece o número de meses que serão pulados em cada divisão. O número de divisões é selecionado pelo parâmetro `slice_limit` e um número não fixo da janela foi definido através do parâmetro `cumulative`. Aumentando o número de divisões teremos uma avaliação mais robusta do modelo, porém há um maior custo computacional.

```{r}
resample_qmly287 <- time_series_cv(
  data = train287_qmly,
  assess = "12 months",
  skip = "36 months",
  cumulative = TRUE,
  slice_limit = 15
)

# Visualização do plano de amostragem
# resample_qmly287 %>%
#  plot_time_series_cv_plan(date,qnat_obs, .interactive = FALSE)
```

 Aplicaremos o PSF a todas as divisões do conjunto de  treinamento para obter uma avaliação robusta do desempenho do modelo. Além disso disso, adicionaremos uma coluna com as previsões usando a média dos parâmetros `k` e `w`.


```{r}
qmly287_slices <- resample_qmly287 %>%
  tk_time_series_cv_plan() %>%
  nest(date, qnat_obs) %>%
  pivot_wider(names_from = .key, values_from = data)

# Previsões usando um horizonte de 12 meses
cv287_qmly <- qmly287_slices %>%
  mutate(
    qnat_pred = map(
      training,
      ~ psf_reprod(.x, n = 12)
    ),
    model = map(
      training,
      ~ psf_reprod(.x, n = 12, predict = FALSE)
    ),
    cvparams = map(model, get_cvpar)
  )


# Média dos parâmetros k e w (2 e 3)
cvm_params <- round(Reduce("+", cv287_qmly[["cvparams"]])
/ length(cv287_qmly[["cvparams"]]), 0)

# Adicionando  coluna com as  prevs usando parâmetros médios
cv287_qmly <- cv287_qmly %>%
  mutate(qnatmpar_pred = map(
    training,
    ~ psf_cvparam(.x, n = 12, params = cvparams)
  ))
```

Iremos comparar o desempenho do modelo com e sem a seleção dos parâmetros pela média.


```{r}
avalcv_m287 <- cv287_qmly %>%
  select(-c("model", "training", "cvparams")) %>%
  group_by(.id) %>%
  unnest() %>%
  summarise(
    KGEpred = KGE(sim = qnat_pred, obs = qnat_obs),
    KGEmpar = KGE(sim = qnatmpar_pred, obs = qnat_obs)
  )  %>% 
  mutate(.id = factor(.id, levels = .id[order(KGEmpar)])) %>% 
  pivot_longer(
    cols = -c(.id),
    names_to = "metric",
    values_to = "valor"
  )

avalcv_m287 %>%
ggplot(aes(x = .id, y = valor)) +
  geom_col() + 
  facet_wrap(~metric, scales = "free_y", nrow = data.table::uniqueN(avalcv_m287$metric)) + 
  theme(axis.text.x = )
```


```{r}
avalcv_m287 %>%
  group_by(metric) %>%
  summarise(
    valor = mean(valor)
  )
```


Verificaremos o desempenho do modelo utilizando os parâmetros médios no conjunto de dados de teste.


```{r}
# Previsões feitas com os parâmetros médios
pcv287_mpar <- psf_cvparam(train287_qmly,
  n = 12,
  params = cvm_params
)
# Previsões sem a seleção dos parâmetros
preds287_qmly <- psf_reprod(train287_qmly, n = 12)

# Previsões e observações
pobs287cv_qmly <- mutate(test287_qmly,
  qnatcv_pred = NA,
  qnat_pred = NA,
  qnatcv_pred = replace(qnatcv_pred,
    values = pcv287_mpar
  ),
  qnat_pred = replace(qnat_pred,
    values = preds287_qmly
  )
)

avalcvmpar_287 <- pobs287cv_qmly %>%
  summarise(
    KGE = KGE(sim = qnat_pred, obs = qnat_obs),
    KGEcv = KGE(sim = qnatcv_pred, obs = qnat_obs)
  )
(avalcvmpar_287)
```

Observamos, baseado na métrica KGE, uma pequena melhora no modelo utilizando a seleção dos parâmetros pela média.


```{r}
posto287cv_xts <- xts(pobs287cv_qmly[,c("qnat_obs","qnatcv_pred","qnat_pred")], 
                   order.by = as.Date(pobs287cv_qmly[["date"]]))
forecast::autoplot(posto287cv_xts, facets = FALSE)+ 
  ylab("Q") + 
  xlab("meses") +
  theme(
    strip.background = element_blank(), 
    strip.text = element_blank()
  )
```









